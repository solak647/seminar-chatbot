cEXT :
5 epoches, direct result

cNEU:
distilbert-base-uncased
5 epochs -> {'mcc': -0.14003848936667812,
 'tp': 517,
 'tn': 546,
 'fp': 650,
 'fn': 764,
 'eval_loss': 3.697997864600151}
really small loss
 3 epochs ->
 {'mcc': -0.057486778299954765,
 'tp': 695,
 'tn': 479,
 'fp': 717,
 'fn': 586,
 'eval_loss': 0.8382400396370119}
 4 epochs avec learning rate Ã  1e-3
 {'mcc': -0.004751339544738071,
 'tp': 949,
 'tn': 305,
 'fp': 891,
 'fn': 332,
 'eval_loss': 0.7028117512502978}
roberta-base
epochs 3
{'mcc': 0.007656626833397047,
 'tp': 1260,
 'tn': 22,
 'fp': 1174,
 'fn': 21,
 'eval_loss': 0.6926074004942371}
albert-base
epochs 3
{'mcc': 0.0,
 'tp': 0,
 'tn': 1239,
 'fp': 0,
 'fn': 1238,
 'eval_loss': 0.7206678808696808}

cCON
distilbert-base-uncased
epoch 5
{'mcc': 0.08536661967776349,
 'tp': 469,
 'tn': 854,
 'fp': 342,
 'fn': 812,
 'eval_loss': 2.9153911560293166}



BEST MODEL:
cCON -> distilbert len 256 epoch 5830 1e-5 -> 0.7637, 0.00025, 0.6897 88%
cEXT -> distilbert len 128 epoch 5 4e-05 -> 0.54 ,...,0.94  77%
cNEU -> distilbert len 512 epoch 2958 1e-5 -> 0.20, 0.26, 0.79  58%
cOPN -> roberta selfmade seq length 300 -> 62.89%, 0.22
cAGR -> roberta selfmade seq length 300 -> 57%, 0.43